{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDjJ_c2gbNsi"
      },
      "source": [
        "# [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) Training notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFCx5J80SGa"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/toddlack/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI_v2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmFP6bN9dvOq"
      },
      "outputs": [],
      "source": [
        "# @title #Check out the graphics card\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwu07JgqoFON"
      },
      "outputs": [],
      "source": [
        "# @title Attach Google Cloud Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjddIFr1oS3W"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "!apt-get -y install build-essential python3-dev ffmpeg\n",
        "!apt -y install -qq aria2\n",
        "%pip install --upgrade setuptools wheel\n",
        "%pip install --upgrade pip\n",
        "%pip install python-dotenv av torchcrepe\n",
        "%pip install faiss-cpu==1.7.2 fairseq-fixed gradio ffmpeg ffmpeg-python praat-parselmouth pyworld numpy numba librosa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge_97mfpgqTm"
      },
      "outputs": [],
      "source": [
        "# @title Clone repo for local use\n",
        "#Clone a repo and cd into the new directory\n",
        "content_root='/content'\n",
        "git_repo='https://github.com/toddlack/Retrieval-based-Voice-Conversion-WebUI.git'\n",
        "app_root=git_repo.split('/')[-1].replace('.git', '')\n",
        "assets_dir=f'{content_root}/{app_root}/assets'\n",
        "%cd {content_root}\n",
        "!git clone {git_repo}\n",
        "%cd {app_root}\n",
        "\n",
        "\n",
        "# !mkdir Retrieval-based-Voice-Conversion-WebUI\n",
        "# %cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "# !git init\n",
        "# !git remote add origin https://github.com/toddlack/Retrieval-based-Voice-Conversion-WebUI.git\n",
        "# !git fetch origin cfd984812804ddc9247d65b14c82cd32e56c1133 --depth=1\n",
        "# !git reset --hard FETCH_HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG3XpUwEomUz"
      },
      "outputs": [],
      "source": [
        "# @title downlad models into the application's 'asset' directory. The web UI will use these.\n",
        "import os\n",
        "os.environ['ASSETS_DIR'] = f'{assets_dir}'\n",
        "# v1\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D32k.pth -d ${ASSETS_DIR}/pretrained -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D40k.pth -d ${ASSETS_DIR}/pretrained -o D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/D48k.pth -d ${ASSETS_DIR}/pretrained -o D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G32k.pth -d ${ASSETS_DIR}/pretrained -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G40k.pth -d ${ASSETS_DIR}/pretrained -o G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/G48k.pth -d ${ASSETS_DIR}/pretrained -o G48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D32k.pth -d ${ASSETS_DIR}/pretrained -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D40k.pth -d ${ASSETS_DIR}/pretrained -o f0D40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0D48k.pth -d ${ASSETS_DIR}/pretrained -o f0D48k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G32k.pth -d ${ASSETS_DIR}/pretrained -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G40k.pth -d ${ASSETS_DIR}/pretrained -o f0G40k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained/f0G48k.pth -d ${ASSETS_DIR}/pretrained -o f0G48k.pth\n",
        "\n",
        "# v2\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D32k.pth -d ${ASSETS_DIR}/pretrained_v2 -o D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D40k.pth -d ${ASSETS_DIR}/pretrained_v2 -o D40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/D48k.pth -d ${ASSETS_DIR}/pretrained_v2 -o D48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G32k.pth -d ${ASSETS_DIR}/pretrained_v2 -o G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G40k.pth -d ${ASSETS_DIR}/pretrained_v2 -o G40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/G48k.pth -d ${ASSETS_DIR}/pretrained_v2 -o G48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D32k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0D32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D40k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0D40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0D48k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0D48k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G32k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0G32k.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G40k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0G40k.pth\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/pretrained_v2/f0G48k.pth -d ${ASSETS_DIR}/pretrained_v2 -o f0G48k.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HugjmZqZRuiF"
      },
      "outputs": [],
      "source": [
        "# @title #Download the vocal separation model\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP2-人声vocals+非人声instrumentals.pth -d ${ASSETS_DIR}/uvr5_weights -o HP2-人声vocals+非人声instrumentals.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/uvr5_weights/HP5-主旋律人声vocals+其他instrumentals.pth -d ${ASSETS_DIR}/uvr5_weights -o HP5-主旋律人声vocals+其他instrumentals.pth\n",
        "\n",
        "#download hubert_base\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt -d ${ASSETS_DIR}/hubert -o hubert_base.pt\n",
        "\n",
        "#Download the RMVPE model\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/rmvpe.pt -d ${ASSETS_DIR}/rmvpe -o rmvpe.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwk7Q0Loqzjx"
      },
      "outputs": [],
      "source": [
        "#Load the packaged dataset from Google Cloud Drive to /content/dataset\n",
        "\n",
        "# @markdown Dataset location - WAV files to train on. Unzip to dataset directory\n",
        "DATASET = \"/content/drive/MyDrive/dataset/tammy20min.zip\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "!mkdir -p /content/dataset\n",
        "!unzip -d /content/dataset -B {DATASET}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDlFxWHWEynD"
      },
      "outputs": [],
      "source": [
        "# @title #Rename the duplicate file in the dataset\n",
        "!ls -a /content/dataset/\n",
        "!rename 's/(\\w+)\\.(\\w+)~(\\d*)/$1_$3.$2/' /content/dataset/*.*~*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vh6vphDwO0b"
      },
      "outputs": [],
      "source": [
        "# @title #Launch Webui\n",
        "\n",
        "%cd /content/Retrieval-based-Voice-Conversion-WebUI\n",
        "#%load_ext tensorboard\n",
        "#%tensorboard --logdir /content/Retrieval-based-Voice-Conversion-WebUI/logs\n",
        "!python3 infer-web.py --colab --pycmd python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgJuNeAwx5Y_"
      },
      "outputs": [],
      "source": [
        "# @title #Manually back up the trained model file to Google Cloud Drive\n",
        "# @markdown #You need to check the file name of the model in the logs folder and manually change the file name at the end of the following command\n",
        "\n",
        "# @markdown #Model Name\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown #Model Epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "# @markdown destination models directory. New model directory created here.\n",
        "DRIVE_DIR = \"ai_voice\"  #@param {type:\"string\"}\n",
        "!mkdir -p /content/drive/MyDrive/ai_voice/{MODELNAME}\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/drive/MyDrive/{DRIVE_DIR}/{MODELNAME}/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/drive/MyDrive/{DRIVE_DIR}/{MODELNAME}/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/added_*.index /content/drive/MyDrive/{DRIVE_DIR}/{MODELNAME}\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/total_*.npy /content/drive/MyDrive/{DRIVE_DIR}/{MODELNAME}\n",
        "\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/assets/weights/{MODELNAME}.pth /content/drive/MyDrive/{DRIVE_DIR}/{MODELNAME}/{MODELNAME}{MODELEPOCH}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVQoLQJXS7WX"
      },
      "outputs": [],
      "source": [
        "# @title Recover from Google Cloud Drive pth\n",
        "# @markdown You need to check the file name of the model in the logs folder and manually change the file name at the end of the following command\n",
        "\n",
        "# @markdown Model name\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Model epoch\n",
        "MODELEPOCH = 7500  # @param {type:\"integer\"}\n",
        "\n",
        "!mkdir -p /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "!cp /content/drive/MyDrive/*.index /content/\n",
        "!cp /content/drive/MyDrive/*.npy /content/\n",
        "!cp /content/drive/MyDrive/{MODELNAME}{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/weights/{MODELNAME}.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAyuKb9J6dz"
      },
      "outputs": [],
      "source": [
        "# @title Manual pre-processing (not recommended)\n",
        "# @markdown Model name\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Sample rate\n",
        "BITRATE = 48000  # @param {type:\"integer\"}\n",
        "# @markdown Number of processes used\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "# @markdown location of audio files to train on.\n",
        "DATA_DIR='/content/dataset' # @param {type:\"string\"}\n",
        "!python3 trainset_preprocess_pipeline_print.py {DATA_DIR} {BITRATE} {THREADCOUNT} logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxJqzAUKmPJ"
      },
      "outputs": [],
      "source": [
        "# @title Manual feature extraction (not recommended)\n",
        "# @markdown Model name\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Number of threads\n",
        "THREADCOUNT = 8  # @param {type:\"integer\"}\n",
        "# @markdown Alogorithm - need list here.\n",
        "ALGO = \"harvest\"  # @param {type:\"string\"}\n",
        "\n",
        "!python3 extract_f0_print.py logs/{MODELNAME} {THREADCOUNT} {ALGO}\n",
        "\n",
        "!python3 extract_feature_print.py cpu 1 0 0 logs/{MODELNAME} True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMLPLKOaKj58"
      },
      "outputs": [],
      "source": [
        "# @title Manual training (not recommended)\n",
        "# @markdown Model name\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown Used GPU\n",
        "USEGPU = \"0\"  # @param {type:\"string\"}\n",
        "# @markdown Batch size\n",
        "BATCHSIZE = 32  # @param {type:\"integer\"}\n",
        "# @markdown Stopped epochs\n",
        "MODELEPOCH = 3200  # @param {type:\"integer\"}\n",
        "# @markdown Nuber of epochs to train\n",
        "EPOCHSAVE = 100  # @param {type:\"integer\"}\n",
        "# @markdown Sample Rate\n",
        "MODELSAMPLE = \"48k\"  # @param {type:\"string\"}\n",
        "# @markdown Whether to cache the training set\n",
        "CACHEDATA = 1  # @param {type:\"integer\"}\n",
        "# @markdown 是否仅保存最新的ckpt文件\n",
        "ONLYLATEST = 0  # @param {type:\"integer\"}\n",
        "\n",
        "!python3 train_nsf_sim_cache_sid_load_pretrain.py -e lulu -sr {MODELSAMPLE} -f0 1 -bs {BATCHSIZE} -g {USEGPU} -te {MODELEPOCH} -se {EPOCHSAVE} -pg pretrained/f0G{MODELSAMPLE}.pth -pd pretrained/f0D{MODELSAMPLE}.pth -l {ONLYLATEST} -c {CACHEDATA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haYA81hySuDl"
      },
      "outputs": [],
      "source": [
        "# @title 删除其它pth，只留选中的（慎点，仔细看代码）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 选中模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"备份选中的模型。。。\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"正在删除。。。\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*.pth\n",
        "\n",
        "!echo \"恢复选中的模型。。。\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"删除完成\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhSiPTVPoIRh"
      },
      "outputs": [],
      "source": [
        "# @title 清除项目下所有文件，只留选中的模型（慎点，仔细看代码）\n",
        "# @markdown 模型名\n",
        "MODELNAME = \"lulu\"  # @param {type:\"string\"}\n",
        "# @markdown 选中模型epoch\n",
        "MODELEPOCH = 9600  # @param {type:\"integer\"}\n",
        "\n",
        "!echo \"备份选中的模型。。。\"\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth /content/{MODELNAME}_D_{MODELEPOCH}.pth\n",
        "!cp /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth /content/{MODELNAME}_G_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"正在删除。。。\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}\n",
        "!rm -rf /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/*\n",
        "\n",
        "!echo \"恢复选中的模型。。。\"\n",
        "!mv /content/{MODELNAME}_D_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/G_{MODELEPOCH}.pth\n",
        "!mv /content/{MODELNAME}_G_{MODELEPOCH}.pth /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}/D_{MODELEPOCH}.pth\n",
        "\n",
        "!echo \"删除完成\"\n",
        "!ls /content/Retrieval-based-Voice-Conversion-WebUI/logs/{MODELNAME}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
